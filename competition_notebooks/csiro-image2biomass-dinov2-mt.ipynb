{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f39278c9",
   "metadata": {
    "papermill": {
     "duration": 0.002199,
     "end_time": "2026-01-08T09:12:32.874348",
     "exception": false,
     "start_time": "2026-01-08T09:12:32.872149",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CSIRO Image2Biomass - DINOv2 Hydra (Multi-GPU + Mixup + Tiling)\n",
    "\n",
    "**Ultimate Performance Strategy:**\n",
    "1. **Backbone**: DINOv2-Base (`vit_base_patch14_dinov2`).\n",
    "2. **Tiling**: Original 1000x2000 crops for maximum leaf-level detail.\n",
    "3. **Mixup**: Blends both Global and Tiled views to improve regression stability.\n",
    "4. **Multi-GPU**: Doubled batch size for 4-hour limit safety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c54d5b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T09:12:32.878377Z",
     "iopub.status.busy": "2026-01-08T09:12:32.878093Z",
     "iopub.status.idle": "2026-01-08T09:12:48.180603Z",
     "shell.execute_reply": "2026-01-08T09:12:48.179826Z"
    },
    "papermill": {
     "duration": 15.306617,
     "end_time": "2026-01-08T09:12:48.182413",
     "exception": false,
     "start_time": "2026-01-08T09:12:32.875796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os, sys, functools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "print = functools.partial(print, flush=True)\n",
    "\n",
    "DATA_DIR = '/kaggle/input/csiro-biomass'\n",
    "CHECKPOINT_DIR = './models_checkpoints'\n",
    "RESUME_PATH = '/kaggle/input/dinov2-tiled/pytorch/default/1/models_checkpoints/best_dino_tiled_fold_1.pth'\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "TARGET_COLUMNS = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'GDM_g', 'Dry_Total_g']\n",
    "TARGET_WEIGHTS = [0.1, 0.1, 0.1, 0.2, 0.5]\n",
    "\n",
    "CONFIG = {\n",
    "    'model_name': 'vit_base_patch14_dinov2.lvd142m', \n",
    "    'img_h': 392, \n",
    "    'img_w': 784,\n",
    "    'tile_size': 392,\n",
    "    'batch_size': 16,     # Multi-GPU Ready\n",
    "    'lr': 1e-4,\n",
    "    'epochs': 20,        # Slightly more epochs for Mixup convergence\n",
    "    'mixup_prob': 0.5,\n",
    "    'alpha': 1.0,\n",
    "    'n_splits': 5,\n",
    "    'device': 'cuda',\n",
    "    'resume_path': '/kaggle/input/dinov2-tiled/pytorch/default/1/models_checkpoints/best_dino_tiled_fold_1.pth'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "659e33b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T09:12:48.186780Z",
     "iopub.status.busy": "2026-01-08T09:12:48.186389Z",
     "iopub.status.idle": "2026-01-08T09:12:48.193876Z",
     "shell.execute_reply": "2026-01-08T09:12:48.193278Z"
    },
    "papermill": {
     "duration": 0.011265,
     "end_time": "2026-01-08T09:12:48.195258",
     "exception": false,
     "start_time": "2026-01-08T09:12:48.183993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GlobalLocalDinoHydra(nn.Module):\n",
    "    def __init__(self, model_name=CONFIG['model_name'], num_species=15):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(model_name, pretrained=True, num_classes=0, dynamic_img_size=True)\n",
    "        embed_dim = self.backbone.num_features\n",
    "        self.meta_reg = nn.Linear(embed_dim * 2, 2) \n",
    "        self.meta_cls = nn.Linear(embed_dim * 2, num_species)\n",
    "        self.species_emb = nn.Embedding(num_species, 32)\n",
    "        fusion_dim = (embed_dim * 2) + 2 + 32\n",
    "        self.heads = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(fusion_dim, 512), nn.GELU(), nn.Dropout(0.1), nn.Linear(512, 1))\n",
    "            for _ in range(5)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x_global, x_tiles):\n",
    "        feat_global = self.backbone(x_global) \n",
    "        B, N, C, H, W = x_tiles.shape\n",
    "        feat_tiles = self.backbone(x_tiles.view(B*N, C, H, W))\n",
    "        feat_tiles = feat_tiles.view(B, N, -1).mean(dim=1) \n",
    "        fused_vis = torch.cat([feat_global, feat_tiles], dim=1)\n",
    "        p_reg = self.meta_reg(fused_vis)\n",
    "        p_cls = self.meta_cls(fused_vis)\n",
    "        # Use argmax for inference even during training (Mixup handles soft labels in loss)\n",
    "        s_emb = self.species_emb(torch.argmax(p_cls, dim=1))\n",
    "        f_all = torch.cat([fused_vis, p_reg, s_emb], dim=1) \n",
    "        out = torch.cat([h(f_all) for h in self.heads], dim=1)\n",
    "        return out, p_reg, p_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5a04b20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T09:12:48.199417Z",
     "iopub.status.busy": "2026-01-08T09:12:48.198853Z",
     "iopub.status.idle": "2026-01-08T09:12:48.203994Z",
     "shell.execute_reply": "2026-01-08T09:12:48.203433Z"
    },
    "papermill": {
     "duration": 0.008595,
     "end_time": "2026-01-08T09:12:48.205239",
     "exception": false,
     "start_time": "2026-01-08T09:12:48.196644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_mixup_tiled(g_imgs, t_imgs, bio_gt, reg_gt, cls_gt, num_species):\n",
    "    if np.random.rand() > CONFIG['mixup_prob']:\n",
    "        return g_imgs, t_imgs, bio_gt, reg_gt, torch.nn.functional.one_hot(cls_gt, num_species).float(), 1.0\n",
    "    \n",
    "    idx = torch.randperm(g_imgs.size(0)).to(g_imgs.device)\n",
    "    lam = np.random.beta(CONFIG['alpha'], CONFIG['alpha'])\n",
    "    \n",
    "    # Mix both global and tiled streams\n",
    "    g_imgs = lam * g_imgs + (1 - lam) * g_imgs[idx]\n",
    "    t_imgs = lam * t_imgs + (1 - lam) * t_imgs[idx]\n",
    "    \n",
    "    bio_gt = lam * bio_gt + (1 - lam) * bio_gt[idx]\n",
    "    reg_gt = lam * reg_gt + (1 - lam) * reg_gt[idx]\n",
    "    \n",
    "    cls_onehot = torch.nn.functional.one_hot(cls_gt, num_species).float()\n",
    "    cls_mixed = lam * cls_onehot + (1 - lam) * cls_onehot[idx]\n",
    "    \n",
    "    return g_imgs, t_imgs, bio_gt, reg_gt, cls_mixed, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3a768c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T09:12:48.209311Z",
     "iopub.status.busy": "2026-01-08T09:12:48.208767Z",
     "iopub.status.idle": "2026-01-08T09:12:48.214684Z",
     "shell.execute_reply": "2026-01-08T09:12:48.214167Z"
    },
    "papermill": {
     "duration": 0.009261,
     "end_time": "2026-01-08T09:12:48.215901",
     "exception": false,
     "start_time": "2026-01-08T09:12:48.206640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HighResTiledDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, tf_global, tf_tile, species_map):\n",
    "        self.df, self.img_dir, self.tf_global, self.tf_tile, self.species_map = df, img_dir, tf_global, tf_tile, species_map\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(os.path.join(self.img_dir, row['image_path'])).convert('RGB')\n",
    "        img_np = np.array(img)\n",
    "        H, W, _ = img_np.shape\n",
    "        img_global = self.tf_global(image=img_np)['image']\n",
    "        mid_w = W // 2\n",
    "        tile_left = img_np[:, :mid_w, :]\n",
    "        tile_right = img_np[:, mid_w:, :]\n",
    "        tiles = [self.tf_tile(image=tile_left)['image'], self.tf_tile(image=tile_right)['image']]\n",
    "        img_tiles = torch.stack(tiles) \n",
    "        bio = torch.tensor(row[TARGET_COLUMNS].values.astype(np.float32))\n",
    "        reg = torch.tensor([row['Pre_GSHH_NDVI'], row['Height_Ave_cm']], dtype=torch.float32)\n",
    "        spec_idx = torch.tensor(self.species_map[row['Species']], dtype=torch.long)\n",
    "        return img_global, img_tiles, bio, reg, spec_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87d1d70e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T09:12:48.219910Z",
     "iopub.status.busy": "2026-01-08T09:12:48.219555Z",
     "iopub.status.idle": "2026-01-08T09:12:48.232696Z",
     "shell.execute_reply": "2026-01-08T09:12:48.232169Z"
    },
    "papermill": {
     "duration": 0.01683,
     "end_time": "2026-01-08T09:12:48.234160",
     "exception": false,
     "start_time": "2026-01-08T09:12:48.217330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def competition_metric(y_true, y_pred):\n",
    "    N = y_true.shape[0]\n",
    "    w = np.tile(TARGET_WEIGHTS, (N, 1)).flatten()\n",
    "    y_t, y_p = y_true.flatten(), y_pred.flatten()\n",
    "    avg = np.sum(w * y_t) / np.sum(w)\n",
    "    res = np.sum(w * (y_t - y_p)**2)\n",
    "    tot = np.sum(w * (y_t - avg)**2)\n",
    "    return 1 - (res/tot) if tot != 0 else 0\n",
    "\n",
    "def train_mixup_tiled(df_wide, species_map):\n",
    "    gkf = GroupKFold(n_splits=CONFIG['n_splits'])\n",
    "    train_idx, val_idx = next(gkf.split(df_wide, groups=df_wide['Sampling_Date']))\n",
    "    train_df, val_df = df_wide.iloc[train_idx], df_wide.iloc[val_idx]\n",
    "    \n",
    "    num_species = len(species_map)\n",
    "    tf_g = A.Compose([A.Resize(CONFIG['img_h'], CONFIG['img_w']), A.HorizontalFlip(), A.Normalize(), ToTensorV2()])\n",
    "    tf_t = A.Compose([A.Resize(CONFIG['tile_size'], CONFIG['tile_size']), A.HorizontalFlip(), A.Normalize(), ToTensorV2()])\n",
    "    \n",
    "    loader_t = DataLoader(HighResTiledDataset(train_df, DATA_DIR, tf_g, tf_t, species_map), batch_size=CONFIG['batch_size'], shuffle=True, num_workers=4, drop_last=True)\n",
    "    loader_v = DataLoader(HighResTiledDataset(val_df, DATA_DIR, tf_g, tf_t, species_map), batch_size=CONFIG['batch_size'], shuffle=False, num_workers=4)\n",
    "    \n",
    "    model = GlobalLocalDinoHydra(num_species=num_species).to(CONFIG['device'])\n",
    "    # LOAD PREVIOUS WEIGHTS\n",
    "    if os.path.exists(CONFIG['resume_path']):\n",
    "        print(f\"Resuming from: {CONFIG['resume_path']}\")\n",
    "        sd = torch.load(CONFIG['resume_path'], map_location=CONFIG['device'])\n",
    "        model.load_state_dict({k.replace('module.', ''): v for k, v in sd.items()})\n",
    "        \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f'Detected {torch.cuda.device_count()} GPUs. Using DataParallel.')\n",
    "        model = nn.DataParallel(model)\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=CONFIG['lr'], weight_decay=0.01)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG['epochs'])\n",
    "    \n",
    "    crit_bio = nn.HuberLoss()\n",
    "    crit_reg = nn.MSELoss()\n",
    "    crit_cls = nn.BCEWithLogitsLoss() # Use BCE for Mixed labels\n",
    "    scaler = torch.amp.GradScaler('cuda')\n",
    "    \n",
    "    best_r2 = -float('inf')\n",
    "    for epoch in range(CONFIG['epochs']):\n",
    "        model.train(); loss_acc = 0\n",
    "        for g, t, b, r, c in loader_t:\n",
    "            g, t, b, r, c = g.to(CONFIG['device']), t.to(CONFIG['device']), b.to(CONFIG['device']), r.to(CONFIG['device']), c.to(CONFIG['device'])\n",
    "            \n",
    "            # Apply Mixup to BOTH streams simultaneously\n",
    "            g_m, t_m, b_m, r_m, c_m, _ = apply_mixup_tiled(g, t, b, r, c, num_species)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                pb, pr, pc = model(g_m, t_m)\n",
    "                loss = crit_bio(pb, b_m) + 0.1*crit_reg(pr, r_m) + 0.2*crit_cls(pc, c_m)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0); scaler.step(optimizer); scaler.update(); loss_acc += loss.item()\n",
    "        \n",
    "        model.eval(); all_p, all_t = [] , []\n",
    "        with torch.no_grad():\n",
    "            for g, t, b, _, _ in loader_v:\n",
    "                p, _, _ = model(g.to(CONFIG['device']), t.to(CONFIG['device']))\n",
    "                all_p.append(p.cpu().numpy()); all_t.append(b.numpy())\n",
    "        \n",
    "        r2 = competition_metric(np.vstack(all_t), np.vstack(all_p))\n",
    "        print(f'Epoch {epoch+1} | R2: {r2:.4f} | Loss: {loss_acc/len(loader_t):.4f}')\n",
    "        if r2 > best_r2: \n",
    "            best_r2 = r2\n",
    "            save_sd = model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict()\n",
    "            torch.save(save_sd, f'{CHECKPOINT_DIR}/best_dino_mixup_tiled.pth')\n",
    "        scheduler.step()\n",
    "    print(f'Final Best R2: {best_r2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4a222ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T09:12:48.238265Z",
     "iopub.status.busy": "2026-01-08T09:12:48.237813Z",
     "iopub.status.idle": "2026-01-08T09:27:56.265869Z",
     "shell.execute_reply": "2026-01-08T09:27:56.264744Z"
    },
    "papermill": {
     "duration": 908.031927,
     "end_time": "2026-01-08T09:27:56.267574",
     "exception": false,
     "start_time": "2026-01-08T09:12:48.235647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Mixup + Tiling + Multi-GPU Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8bd16949b45411681b38e8627817fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from: /kaggle/input/dinov2-tiled/pytorch/default/1/models_checkpoints/best_dino_tiled_fold_1.pth\n",
      "Detected 2 GPUs. Using DataParallel.\n",
      "Epoch 1 | R2: 0.6261 | Loss: 14.0349\n",
      "Epoch 2 | R2: 0.4035 | Loss: 12.7722\n",
      "Epoch 3 | R2: 0.3498 | Loss: 15.8199\n",
      "Epoch 4 | R2: 0.3494 | Loss: 13.9585\n",
      "Epoch 5 | R2: 0.4627 | Loss: 11.7235\n",
      "Epoch 6 | R2: 0.5446 | Loss: 10.7164\n",
      "Epoch 7 | R2: 0.5318 | Loss: 10.3651\n",
      "Epoch 8 | R2: 0.3576 | Loss: 9.9597\n",
      "Epoch 9 | R2: 0.5305 | Loss: 9.5868\n",
      "Epoch 10 | R2: 0.6136 | Loss: 8.2950\n",
      "Epoch 11 | R2: 0.5992 | Loss: 8.0576\n",
      "Epoch 12 | R2: 0.6982 | Loss: 7.4100\n",
      "Epoch 13 | R2: 0.6633 | Loss: 6.3249\n",
      "Epoch 14 | R2: 0.6951 | Loss: 6.9932\n",
      "Epoch 15 | R2: 0.6719 | Loss: 6.3986\n",
      "Epoch 16 | R2: 0.7350 | Loss: 5.4784\n",
      "Epoch 17 | R2: 0.7348 | Loss: 5.6322\n",
      "Epoch 18 | R2: 0.7159 | Loss: 6.0133\n",
      "Epoch 19 | R2: 0.7232 | Loss: 4.6080\n",
      "Epoch 20 | R2: 0.7258 | Loss: 5.4030\n",
      "Final Best R2: 0.7350\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
    "df_wide = df.pivot_table(index=['image_path', 'Sampling_Date', 'Species', 'Pre_GSHH_NDVI', 'Height_Ave_cm'], columns='target_name', values='target').reset_index()\n",
    "species_map = {s: i for i, s in enumerate(sorted(df_wide['Species'].unique()))}\n",
    "print('Starting Mixup + Tiling + Multi-GPU Training...')\n",
    "train_mixup_tiled(df_wide, species_map)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "sourceId": 112509,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 554860,
     "modelInstanceId": 541664,
     "sourceId": 712879,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 928.539356,
   "end_time": "2026-01-08T09:27:58.920990",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-08T09:12:30.381634",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "17e3b9e4a6b54700b83f84fa2e395d5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1e7fcf9b04d545d6bb6e4ab9f258e01a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2a3f6ca1ba3c48688161676b3788018a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "38f34b390d86434db8638bccc0bd59eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2a3f6ca1ba3c48688161676b3788018a",
       "max": 346334872.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1e7fcf9b04d545d6bb6e4ab9f258e01a",
       "tabbable": null,
       "tooltip": null,
       "value": 346334872.0
      }
     },
     "6136ca2d2922403eb0d8bd53aad1e0e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9c6e9ab15f9b40328523aa25c525c60d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a5304321b27840179f00b7ae6b067489": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b42c123a29db4f168bcd7b22c235b73e",
       "placeholder": "​",
       "style": "IPY_MODEL_17e3b9e4a6b54700b83f84fa2e395d5c",
       "tabbable": null,
       "tooltip": null,
       "value": " 346M/346M [00:01&lt;00:00, 402MB/s]"
      }
     },
     "b42c123a29db4f168bcd7b22c235b73e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b8bd16949b45411681b38e8627817fba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f03486abb8ca4362b2c46f21a534fdd1",
        "IPY_MODEL_38f34b390d86434db8638bccc0bd59eb",
        "IPY_MODEL_a5304321b27840179f00b7ae6b067489"
       ],
       "layout": "IPY_MODEL_f6caa17e9a7c4b75885493e379062bfd",
       "tabbable": null,
       "tooltip": null
      }
     },
     "f03486abb8ca4362b2c46f21a534fdd1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9c6e9ab15f9b40328523aa25c525c60d",
       "placeholder": "​",
       "style": "IPY_MODEL_6136ca2d2922403eb0d8bd53aad1e0e2",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "f6caa17e9a7c4b75885493e379062bfd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
