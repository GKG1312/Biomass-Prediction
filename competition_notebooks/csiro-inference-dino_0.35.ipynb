{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11747e2a",
   "metadata": {
    "papermill": {
     "duration": 0.001969,
     "end_time": "2026-01-08T09:47:32.286987",
     "exception": false,
     "start_time": "2026-01-08T09:47:32.285018",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CSIRO Image2Biomass - DINOv2 Tiling Inference (Kaggle Offline Ready)\n",
    "\n",
    "**Improvements:**\n",
    "1. **Fixed Image Mapping**: Corrected the index math for mapping batches to image paths.\n",
    "2. **Unique Image Processing**: Only processes each test image once (5x speedup).\n",
    "3. **Memory Safety**: Optimized for T4 GPU (Batch Size 8).\n",
    "4. **Strict Offline**: No network calls during model creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4128299",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T09:47:32.290727Z",
     "iopub.status.busy": "2026-01-08T09:47:32.290273Z",
     "iopub.status.idle": "2026-01-08T09:48:18.894759Z",
     "shell.execute_reply": "2026-01-08T09:48:18.893982Z"
    },
    "papermill": {
     "duration": 46.609111,
     "end_time": "2026-01-08T09:48:18.897387",
     "exception": false,
     "start_time": "2026-01-08T09:47:32.288276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/albumentations/check_version.py:147: UserWarning: Error fetching version info <urlopen error [Errno -3] Temporary failure in name resolution>\n",
      "  data = fetch_version_info()\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f95cac2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T09:48:18.901338Z",
     "iopub.status.busy": "2026-01-08T09:48:18.900884Z",
     "iopub.status.idle": "2026-01-08T09:48:18.981592Z",
     "shell.execute_reply": "2026-01-08T09:48:18.980877Z"
    },
    "papermill": {
     "duration": 0.084228,
     "end_time": "2026-01-08T09:48:18.982982",
     "exception": false,
     "start_time": "2026-01-08T09:48:18.898754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = '/kaggle/input/csiro-biomass'\n",
    "# Update this path to where you attached your model checkpoint\n",
    "CHECKPOINT_PATH = '/kaggle/input/dinov2-mt/pytorch/default/1/models_checkpoints/best_dino_mixup_tiled.pth'\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "TARGET_COLUMNS = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'GDM_g', 'Dry_Total_g']\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac52ca92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T09:48:18.987323Z",
     "iopub.status.busy": "2026-01-08T09:48:18.986762Z",
     "iopub.status.idle": "2026-01-08T09:48:18.993982Z",
     "shell.execute_reply": "2026-01-08T09:48:18.993287Z"
    },
    "papermill": {
     "duration": 0.010792,
     "end_time": "2026-01-08T09:48:18.995348",
     "exception": false,
     "start_time": "2026-01-08T09:48:18.984556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GlobalLocalDinoHydra(nn.Module):\n",
    "    def __init__(self, model_name='vit_base_patch14_dinov2.lvd142m', num_species=15):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(model_name, pretrained=False, num_classes=0, dynamic_img_size=True)\n",
    "        embed_dim = self.backbone.num_features\n",
    "        self.meta_reg = nn.Linear(embed_dim * 2, 2) \n",
    "        self.meta_cls = nn.Linear(embed_dim * 2, num_species)\n",
    "        self.species_emb = nn.Embedding(num_species, 32)\n",
    "        fusion_dim = (embed_dim * 2) + 2 + 32\n",
    "        self.heads = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(fusion_dim, 512), nn.GELU(), nn.Dropout(0.1), nn.Linear(512, 1))\n",
    "            for _ in range(5)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x_global, x_tiles):\n",
    "        feat_global = self.backbone(x_global) \n",
    "        B, N, C, H, W = x_tiles.shape\n",
    "        feat_tiles = self.backbone(x_tiles.view(B*N, C, H, W))\n",
    "        feat_tiles = feat_tiles.view(B, N, -1).mean(dim=1) \n",
    "        fused_vis = torch.cat([feat_global, feat_tiles], dim=1)\n",
    "        p_reg = self.meta_reg(fused_vis)\n",
    "        p_cls = self.meta_cls(fused_vis)\n",
    "        s_emb = self.species_emb(torch.argmax(p_cls, dim=1))\n",
    "        f_all = torch.cat([fused_vis, p_reg, s_emb], dim=1) \n",
    "        out = torch.cat([h(f_all) for h in self.heads], dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86e5cada",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T09:48:18.999234Z",
     "iopub.status.busy": "2026-01-08T09:48:18.998866Z",
     "iopub.status.idle": "2026-01-08T09:48:19.004276Z",
     "shell.execute_reply": "2026-01-08T09:48:19.003682Z"
    },
    "papermill": {
     "duration": 0.008849,
     "end_time": "2026-01-08T09:48:19.005616",
     "exception": false,
     "start_time": "2026-01-08T09:48:18.996767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, tf_global, tf_tile):\n",
    "        self.df, self.img_dir, self.tf_global, self.tf_tile = df, img_dir, tf_global, tf_tile\n",
    "        \n",
    "    def __len__(self): return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.img_dir, row['image_path'])\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img_np = np.array(img)\n",
    "        H, W, _ = img_np.shape\n",
    "        img_global = self.tf_global(image=img_np)['image']\n",
    "        mid_w = W // 2\n",
    "        tile_left = img_np[:, :mid_w, :]\n",
    "        tile_right = img_np[:, mid_w:, :]\n",
    "        img_tiles = torch.stack([\n",
    "            self.tf_tile(image=tile_left)['image'],\n",
    "            self.tf_tile(image=tile_right)['image']\n",
    "        ])\n",
    "        return img_global, img_tiles, row['image_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71ee8d0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-08T09:48:19.009384Z",
     "iopub.status.busy": "2026-01-08T09:48:19.009157Z",
     "iopub.status.idle": "2026-01-08T09:48:25.177963Z",
     "shell.execute_reply": "2026-01-08T09:48:25.176931Z"
    },
    "papermill": {
     "duration": 6.172645,
     "end_time": "2026-01-08T09:48:25.179655",
     "exception": false,
     "start_time": "2026-01-08T09:48:19.007010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights: /kaggle/input/dinov2-mt/pytorch/default/1/models_checkpoints/best_dino_mixup_tiled.pth\n",
      "Submission file saved successfully!\n",
      "                    sample_id             image_path   target_name     target\n",
      "0  ID1001187975__Dry_Clover_g  test/ID1001187975.jpg  Dry_Clover_g   0.904442\n",
      "1    ID1001187975__Dry_Dead_g  test/ID1001187975.jpg    Dry_Dead_g  24.447477\n",
      "2   ID1001187975__Dry_Green_g  test/ID1001187975.jpg   Dry_Green_g  28.540804\n",
      "3   ID1001187975__Dry_Total_g  test/ID1001187975.jpg   Dry_Total_g  57.467464\n",
      "4         ID1001187975__GDM_g  test/ID1001187975.jpg         GDM_g  29.460234\n"
     ]
    }
   ],
   "source": [
    "def run_inference():\n",
    "    model = GlobalLocalDinoHydra().to(DEVICE)\n",
    "    if os.path.exists(CHECKPOINT_PATH):\n",
    "        print(f'Loading weights: {CHECKPOINT_PATH}')\n",
    "        sd = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
    "        sd = {k.replace(\"module.\", \"\"): v for k, v in sd.items()}\n",
    "        model.load_state_dict(sd)\n",
    "    else:\n",
    "        print('CRITICAL: Checkpoint not found!')\n",
    "    model.eval()\n",
    "    \n",
    "    test_df = pd.read_csv(os.path.join(DATA_DIR, 'test.csv'))\n",
    "    unique_images = test_df[['image_path']].drop_duplicates()\n",
    "    \n",
    "    tf_g = A.Compose([A.Resize(392, 784), A.Normalize(), ToTensorV2()])\n",
    "    tf_t = A.Compose([A.Resize(392, 392), A.Normalize(), ToTensorV2()])\n",
    "    \n",
    "    ds = InferenceDataset(unique_images, DATA_DIR, tf_g, tf_t)\n",
    "    loader = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "    \n",
    "    all_results = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (g_imgs, t_imgs, paths) in enumerate(loader):\n",
    "            preds = model(g_imgs.to(DEVICE), t_imgs.to(DEVICE)).cpu().numpy()\n",
    "            for b in range(preds.shape[0]):\n",
    "                img_path = paths[b]\n",
    "                for i, target_name in enumerate(TARGET_COLUMNS):\n",
    "                    all_results.append({\n",
    "                        'image_path': img_path,\n",
    "                        'target_name': target_name,\n",
    "                        'target': max(0.0, float(preds[b, i]))\n",
    "                    })\n",
    "            if (batch_idx + 1) % 10 == 0: \n",
    "                print(f'Processed {(batch_idx+1)*BATCH_SIZE} images...')\n",
    "\n",
    "    pred_df = pd.DataFrame(all_results)\n",
    "    submission = test_df.merge(pred_df, on=['image_path', 'target_name'], how='left')\n",
    "    submission[['sample_id', 'target']].to_csv('submission.csv', index=False)\n",
    "    print('Submission file saved successfully!')\n",
    "    print(submission.head())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_inference()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "sourceId": 112509,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 552161,
     "modelInstanceId": 538914,
     "sourceId": 709496,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 554860,
     "modelInstanceId": 541664,
     "sourceId": 712879,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 555044,
     "modelInstanceId": 541850,
     "sourceId": 713099,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 57.996315,
   "end_time": "2026-01-08T09:48:27.916989",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-08T09:47:29.920674",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
