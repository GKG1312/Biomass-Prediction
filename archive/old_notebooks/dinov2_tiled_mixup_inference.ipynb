{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1",
      "metadata": {},
      "source": [
        "# CSIRO DINOv2 Tiling + Fold Ensemble Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, pd, numpy as np, torch, timm, albumentations as A\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n\n",
        "DATA_DIR = '/kaggle/input/csiro-biomass'\n",
        "PATHS = ['/kaggle/input/your-dino-weights/dino_fold0.pth', '/kaggle/input/your-dino-weights/dino_fold1.pth']\n",
        "ENSEMBLE_WEIGHTS = [0.6, 0.4] # Tweak weights here! Must match number of models found.\n",
        "TARGET_COLUMNS = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3",
      "metadata": {},
      "outputs": [],
      "source": [
        "class GlobalLocalDinoHydra(nn.Module):\n",
        "    def __init__(self, model_name='vit_base_patch14_dinov2.lvd142m', num_species=15):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(model_name, pretrained=False, num_classes=0, dynamic_img_size=True)\n",
        "        d = self.backbone.num_features\n",
        "        self.meta_reg = nn.Linear(d*2, 2); self.meta_cls = nn.Linear(d*2, num_species)\n",
        "        self.species_emb = nn.Embedding(num_species, 32)\n",
        "        self.heads = nn.ModuleList([nn.Sequential(nn.Linear(d*2+2+32, 512), nn.GELU(), nn.Linear(512, 1)) for _ in range(5)])\n",
        "    def forward(self, x_g, x_t):\n",
        "        fg = self.backbone(x_g)\n",
        "        B, N, C, H, W = x_t.shape\n",
        "        ft = self.backbone(x_t.view(B*N, C, H, W)).view(B, N, -1).mean(1)\n",
        "        v = torch.cat([fg, ft], dim=1)\n",
        "        pr, pc = self.meta_reg(v), self.meta_cls(v)\n",
        "        se = self.species_emb(pc.argmax(1))\n",
        "        fus = torch.cat([v, pr, se], dim=1)\n",
        "        return torch.cat([h(fus) for h in self.heads], dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run():\n",
        "    models = []\n",
        "    for p in PATHS:\n",
        "        if os.path.exists(p):\n",
        "            m = GlobalLocalDinoHydra().cuda().eval()\n",
        "            sd = torch.load(p, map_location='cuda')\n",
        "            m.load_state_dict({k.replace('module.',''): v for k,v in sd.items()})\n",
        "            models.append(m)\n",
        "            print(f'Loaded: {p}')\n\n",
        "    if not models:\n",
        "        print('No models found!')\n",
        "        return\n\n",
        "    test = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
        "    uni = test[['image_path']].drop_duplicates()\n",
        "    tf_g = A.Compose([A.Resize(392, 784), A.Normalize(), ToTensorV2()])\n",
        "    tf_t = A.Compose([A.Resize(392, 392), A.Normalize(), ToTensorV2()])\n\n",
        "    class InfDs(Dataset):\n",
        "        def __len__(self): return len(uni)\n",
        "        def __getitem__(self, i):\n",
        "            p = uni.iloc[i]['image_path']; img = np.array(Image.open(f'{DATA_DIR}/{p}').convert('RGB'))\n",
        "            mid = img.shape[1]//2\n",
        "            g = tf_g(image=img)['image']\n",
        "            t = torch.stack([tf_t(image=img[:, :mid])['image'], tf_t(image=img[:, mid:])['image']])\n",
        "            return g, t, p\n\n",
        "    ld = DataLoader(InfDs(), batch_size=8)\n",
        "    res = []\n",
        "    with torch.no_grad():\n",
        "        for g, t, ps in ld:\n",
        "            fps = []\n",
        "            for m in models: fps.append(m(g.cuda(), t.cuda()).cpu().numpy())\n",
        "            \n",
        "            # Weighted Averaging logic\n",
        "            w = np.array(ENSEMBLE_WEIGHTS[:len(models)])\n",
        "            w = w / w.sum()\n",
        "            avg = np.zeros_like(fps[0])\n",
        "            for i in range(len(fps)): avg += fps[i] * w[i]\n\n",
        "            for b in range(len(ps)):\n",
        "                for i, col in enumerate(TARGET_COLUMNS):\n",
        "                    res.append({'image_path': ps[b], 'target_name': col, 'target': max(0.0, float(avg[b,i]))})\n\n",
        "    out = pd.DataFrame(res)\n",
        "    sub = test[['sample_id', 'image_path', 'target_name']].merge(out, on=['image_path','target_name'], how='left')\n",
        "    sub[['sample_id', 'target']].to_csv('submission.csv', index=False)\n",
        "    print('Submission saved with weighted ensemble.')\n\n",
        "run()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "isInternetEnabled": false,
      "isGpuEnabled": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}