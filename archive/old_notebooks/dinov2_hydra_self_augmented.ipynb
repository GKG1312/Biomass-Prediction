{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "5acc6f06",
            "metadata": {},
            "source": [
                "# CSIRO Image2Biomass - DINOv2 Hydra (Kaggle Stable Version)\n",
                "\n",
                "**Stability Fixes:**\n",
                "1. **Force Print Flushing**: Ensures logs appear immediately without buffering.\n",
                "2. **Progress File Logging**: Progress is written to `training_log.txt` so you can verify it even if the UI hangs.\n",
                "3. **DataParallel drop_last**: Prevents the Multi-GPU crash we saw earlier."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "453119e1",
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q -U albumentations timm opencv-python-headless kagglehub"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dc533ea7",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, sys, functools\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from PIL import Image\n",
                "import timm\n",
                "import albumentations as A\n",
                "from albumentations.pytorch import ToTensorV2\n",
                "from sklearn.model_selection import GroupKFold\n",
                "import kagglehub\n",
                "\n",
                "# STABILITY FIX: Force print to flush so UI doesn't hang\n",
                "print = functools.partial(print, flush=True)\n",
                "\n",
                "def log_to_file(message):\n",
                "    with open(\"training_log.txt\", \"a\") as f:\n",
                "        f.write(message + \"\\n\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e4eae2af",
            "metadata": {},
            "outputs": [],
            "source": [
                "DATA_DIR = \"/kaggle/input/csiro-biomass\"\n",
                "CHECKPOINT_DIR = \"./models_checkpoints\"\n",
                "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
                "log_to_file(\"--- Session Started ---\")\n",
                "\n",
                "TARGET_COLUMNS = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'GDM_g', 'Dry_Total_g']\n",
                "TARGET_WEIGHTS = [0.1, 0.1, 0.1, 0.2, 0.5]\n",
                "\n",
                "CONFIG = {\n",
                "    \"model_name\": \"vit_base_patch14_dinov2.lvd142m\", \n",
                "    \"img_h\": 392, \n",
                "    \"img_w\": 784,\n",
                "    \"batch_size\": 16, \n",
                "    \"lr\": 1e-4,\n",
                "    \"epochs\": 30,\n",
                "    \"n_splits\": 5,\n",
                "    \"meta_weight\": 0.2,\n",
                "    \"kaggle_username\": \"girish2002\",\n",
                "    \"model_slug\": \"CSIRO_Dino_SelfAugmented\",\n",
                "    \"device\": \"cuda\"\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "model_def",
            "metadata": {},
            "outputs": [],
            "source": [
                "def competition_metric(y_true, y_pred):\n",
                "    N = y_true.shape[0]\n",
                "    weights = np.array(TARGET_WEIGHTS)\n",
                "    w = np.tile(weights, (N, 1))\n",
                "    y_true_f, y_pred_f, w_f = y_true.flatten(), y_pred.flatten(), w.flatten()\n",
                "    y_avg_w = np.sum(w_f * y_true_f) / np.sum(w_f)\n",
                "    ss_res = np.sum(w_f * (y_true_f - y_pred_f)**2)\n",
                "    ss_tot = np.sum(w_f * (y_true_f - y_avg_w)**2)\n",
                "    return 1 - (ss_res / ss_tot) if ss_tot != 0 else 0.0\n",
                "\n",
                "class SelfAugmentedHydraDINO(nn.Module):\n",
                "    def __init__(self, model_name=CONFIG['model_name'], pretrained=True):\n",
                "        super().__init__()\n",
                "        self.backbone = timm.create_model(model_name, pretrained=pretrained, num_classes=0, dynamic_img_size=True)\n",
                "        embed_dim = self.backbone.num_features\n",
                "        self.meta_predictor = nn.Sequential(nn.Linear(embed_dim, 128), nn.GELU(), nn.Linear(128, 3))\n",
                "        fusion_dim = embed_dim + 3\n",
                "        self.head_clover = nn.Sequential(nn.Linear(fusion_dim, 256), nn.GELU(), nn.Linear(256, 1))\n",
                "        self.head_dead   = nn.Sequential(nn.Linear(fusion_dim, 256), nn.GELU(), nn.Linear(256, 1))\n",
                "        self.head_green  = nn.Sequential(nn.Linear(fusion_dim, 256), nn.GELU(), nn.Linear(256, 1))\n",
                "        self.head_gdm    = nn.Sequential(nn.Linear(fusion_dim, 256), nn.GELU(), nn.Linear(256, 1))\n",
                "        self.head_total  = nn.Sequential(nn.Linear(fusion_dim, 256), nn.GELU(), nn.Linear(256, 1))\n",
                "        \n",
                "    def forward(self, image, return_meta=False):\n",
                "        feats = self.backbone(image)\n",
                "        pred_meta = self.meta_predictor(feats)\n",
                "        combined = torch.cat([feats, pred_meta], dim=1)\n",
                "        out = torch.cat([\n",
                "            self.head_clover(combined), self.head_dead(combined),\n",
                "            self.head_green(combined), self.head_gdm(combined), self.head_total(combined)\n",
                "        ], dim=1)\n",
                "        if return_meta: return out, pred_meta\n",
                "        return out"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "train_logic",
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_fold(fold, train_df, val_df, species_map):\n",
                "    train_ds = SelfAugmentedDataset(train_df, DATA_DIR, A.Compose([A.Resize(CONFIG['img_h'], CONFIG['img_w']), A.HorizontalFlip(), A.Normalize(), ToTensorV2()]), species_map)\n",
                "    val_ds = SelfAugmentedDataset(val_df, DATA_DIR, A.Compose([A.Resize(CONFIG['img_h'], CONFIG['img_w']), A.Normalize(), ToTensorV2()]), species_map)\n",
                "    \n",
                "    train_loader = DataLoader(train_ds, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=4, drop_last=True)\n",
                "    val_loader = DataLoader(val_ds, batch_size=CONFIG['batch_size'], shuffle=False)\n",
                "    \n",
                "    model = SelfAugmentedHydraDINO(pretrained=True).to(CONFIG['device'])\n",
                "    if torch.cuda.device_count() > 1:\n",
                "        model = nn.DataParallel(model)\n",
                "    \n",
                "    optimizer = optim.AdamW(model.parameters(), lr=CONFIG['lr'])\n",
                "    criterion_bio = nn.HuberLoss()\n",
                "    criterion_meta = nn.MSELoss()\n",
                "    \n",
                "    fold_best_r2 = -float('inf')\n",
                "    best_sd = None\n",
                "    \n",
                "    for epoch in range(CONFIG['epochs']):\n",
                "        model.train()\n",
                "        for imgs, bios, metas in train_loader:\n",
                "            imgs, bios, metas = imgs.to(CONFIG['device']), bios.to(CONFIG['device']), metas.to(CONFIG['device'])\n",
                "            optimizer.zero_grad()\n",
                "            p_bio, p_meta = model(imgs, return_meta=True)\n",
                "            loss = criterion_bio(p_bio, bios) + CONFIG['meta_weight'] * criterion_meta(p_meta, metas)\n",
                "            loss.backward()\n",
                "            optimizer.step()\n",
                "            \n",
                "        model.eval()\n",
                "        all_preds, all_targets = [], []\n",
                "        with torch.no_grad():\n",
                "            for imgs, bios, _ in val_loader:\n",
                "                imgs = imgs.to(CONFIG['device'])\n",
                "                all_preds.append(model(imgs).cpu().numpy())\n",
                "                all_targets.append(bios.numpy())\n",
                "        \n",
                "        r2 = competition_metric(np.vstack(all_targets), np.vstack(all_preds))\n",
                "        status = f\"Fold {fold} | Epoch {epoch+1} | R2: {r2:.4f}\"\n",
                "        print(status)\n",
                "        log_to_file(status)\n",
                "        \n",
                "        if r2 > fold_best_r2:\n",
                "            fold_best_r2 = r2\n",
                "            best_sd = model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict()\n",
                "            \n",
                "    return fold_best_r2, best_sd"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dataset_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "class SelfAugmentedDataset(Dataset):\n",
                "    def __init__(self, df, img_dir, transform=None, species_map=None):\n",
                "        self.df = df\n",
                "        self.img_dir = img_dir\n",
                "        self.transform = transform\n",
                "        self.species_map = species_map\n",
                "    def __len__(self): return len(self.df)\n",
                "    def __getitem__(self, idx):\n",
                "        row = self.df.iloc[idx]\n",
                "        image = np.array(Image.open(os.path.join(self.img_dir, row['image_path'])).convert('RGB'))\n",
                "        if self.transform: image = self.transform(image=image)['image']\n",
                "        biomass = torch.tensor(row[TARGET_COLUMNS].values.astype(np.float32))\n",
                "        meta = torch.tensor([row['Pre_GSHH_NDVI'], row['Height_Ave_cm'], float(self.species_map[row['Species']])], dtype=torch.float32)\n",
                "        return image, biomass, meta\n",
                "\n",
                "df = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"))\n",
                "df_wide = df.pivot_table(index=['image_path', 'Sampling_Date', 'State', 'Species', 'Pre_GSHH_NDVI', 'Height_Ave_cm'], \n",
                "                       columns='target_name', \n",
                "                       values='target').reset_index()\n",
                "\n",
                "species_map = {s: i for i, s in enumerate(sorted(df_wide['Species'].unique()))}\n",
                "overall_best_r2 = -float('inf')\n",
                "overall_best_sd = None\n",
                "\n",
                "gkf = GroupKFold(n_splits=CONFIG['n_splits'])\n",
                "for fold, (t, v) in enumerate(gkf.split(df_wide, groups=df_wide['Sampling_Date'])):\n",
                "    msg = f\"\\n--- Training Fold {fold} ---\"\n",
                "    print(msg); log_to_file(msg)\n",
                "    score, sd = train_fold(fold, df_wide.iloc[t], df_wide.iloc[v], species_map)\n",
                "    \n",
                "    if score > overall_best_r2:\n",
                "        overall_best_r2 = score\n",
                "        overall_best_sd = sd\n",
                "\n",
                "if overall_best_sd is not None:\n",
                "    final_path = os.path.join(CHECKPOINT_DIR, \"best_dino_self_aug_global.pth\")\n",
                "    torch.save(overall_best_sd, final_path)\n",
                "    try:\n",
                "        handle = f\"{CONFIG['kaggle_username']}/{CONFIG['model_slug']}/pytorch/default\"\n",
                "        kagglehub.model_upload(handle=handle, local_model_dir=os.path.dirname(final_path), version_notes=f\"Global Best R2: {overall_best_r2:.4f}\")\n",
                "        log_to_file(\"Upload Successful\")\n",
                "    except Exception as e: log_to_file(f\"Upload Failed: {e}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": { \"display_name\": \"Python 3\", \"language\": \"python\", \"name\": \"python3\" },"language_info": { \"codemirror_mode\": { \"name\": \"ipython\", \"version\": 3 }, \"file_extension\": \".py\", \"mimetype\": \"text/x-python\", \"name\": \"python\", \"nbconvert_exporter\": \"python\", \"pygments_lexer\": \"ipython3\", \"version\": \"3.10.0\" }
            },
            "nbformat": 4, \"nbformat_minor\": 5
        }