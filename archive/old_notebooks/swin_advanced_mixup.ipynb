{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 112509,
     "databundleVersionId": 14254895,
     "sourceType": "competition"
    },
    {
     "sourceId": 715996,
     "sourceType": "modelInstanceVersion",
     "isSourceIdPinned": true,
     "modelInstanceId": 540620,
     "modelId": 553813
    }
   ],
   "dockerImageVersionId": 31234,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# CSIRO Image2Biomass - Swin-V2 with Mixup Augmentation\n\nThis notebook implements the **Mixup** augmentation strategy for the `AdvancedSwinHydra` model. Mixup helps the model generalize by creating \"virtual\" training examples that are linear combinations of image pairs and their target biomass/metadata values.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import os, sys, functools\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport timm\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom sklearn.model_selection import GroupKFold\n\nDATA_DIR = \"/kaggle/input/csiro-biomass\"\nCHECKPOINT_DIR = \"./models_checkpoints\"\nos.makedirs(CHECKPOINT_DIR, exist_ok=True)\n\nTARGET_COLUMNS = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'GDM_g', 'Dry_Total_g']\nTARGET_WEIGHTS = [0.1, 0.1, 0.1, 0.2, 0.5]\n\nCONFIG = {\n    \"model_name\": \"swinv2_large_window12_192.ms_in22k\", \n    \"img_h\": 384, \n    \"img_w\": 768,\n    \"batch_size\": 8, \n    \"lr\": 5e-6, \n    \"epochs\": 50,\n    \"n_splits\": 5,\n    \"mixup_prob\": 0.4,\n    \"alpha\": 1.0,\n    \"device\": \"cuda\",\n    # UPDATE THIS PATH TO YOUR SAVED WEIGHTS FILE\n    \"resume_path\": None\n    # \"resume_path\": \"/kaggle/input/swin-mixup-kfold/pytorch/default/4/models_checkpoints/best_swinv2_large_ft_fold4.pth\" \n}",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-13T14:50:28.622950Z",
     "iopub.execute_input": "2026-01-13T14:50:28.623146Z",
     "iopub.status.idle": "2026-01-13T14:50:41.816405Z",
     "shell.execute_reply.started": "2026-01-13T14:50:28.623126Z",
     "shell.execute_reply": "2026-01-13T14:50:41.815844Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": "class AdvancedSwinHydra(nn.Module):\n    def __init__(self, model_name=CONFIG['model_name'], num_species=15, num_region=4):\n        super().__init__()\n        try:\n            self.backbone = timm.create_model(\n                model_name, \n                pretrained=True, \n                num_classes=0, global_pool='avg', \n                img_size=(CONFIG['img_h'], CONFIG['img_w'])\n            )\n        except Exception as e:\n            base_name = model_name.split('.')[0]\n            self.backbone = timm.create_model(\n                base_name, \n                pretrained=True, \n                num_classes=0, global_pool='avg', \n                img_size=(CONFIG['img_h'], CONFIG['img_w'])\n            )\n            \n        embed_dim = self.backbone.num_features\n        self.meta_reg = nn.Linear(embed_dim, 2) \n        self.meta_cls = nn.Linear(embed_dim, num_species)\n        self.meta_rgn = nn.Linear(embed_dim, num_region)\n        self.species_emb = nn.Embedding(num_species, 32)\n        self.region_emb = nn.Embedding(num_region, 16)\n        \n        fusion_dim = embed_dim + 2 + 32 + 16\n        self.heads = nn.ModuleList([nn.Sequential(nn.Linear(fusion_dim, 256), nn.GELU(), nn.Linear(256, 1)) for _ in range(5)])\n        \n    def forward(self, x, return_meta=False):\n        feat = self.backbone(x)\n        p_reg = self.meta_reg(feat)\n        p_cls = self.meta_cls(feat)\n        p_rgn = self.meta_rgn(feat)\n        \n        spec_idx = torch.argmax(p_cls, dim=-1)\n        rgn_idx = torch.argmax(p_rgn, dim=-1)\n        s_emb = self.species_emb(spec_idx)\n        rgn_emb = self.region_emb(rgn_idx)\n        \n        fusion = torch.cat([feat, p_reg, s_emb, rgn_emb], dim=-1)\n        out = torch.cat([h(fusion) for h in self.heads], dim=-1)\n        \n        if return_meta: return out, p_reg, p_cls, p_rgn\n        return out",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-06T09:56:18.312595Z",
     "iopub.execute_input": "2026-01-06T09:56:18.313139Z",
     "iopub.status.idle": "2026-01-06T09:56:18.320722Z",
     "shell.execute_reply.started": "2026-01-06T09:56:18.313111Z",
     "shell.execute_reply": "2026-01-06T09:56:18.320055Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "def apply_mixup(images, bio_gt, reg_gt, cls_gt, plc_gt, num_species, num_region):\n    \"\"\"\n    Blends two images and their labels.\n    Images: Weighted average of pixels.\n    Labels (Regression): Weighted average of values.\n    Labels (Species): Weighted average of one-hot vectors.\n    Labels (State): Weighted average of one-hot vectors.\n    \"\"\"\n    if np.random.rand() > CONFIG['mixup_prob']:\n        return images, bio_gt, reg_gt, torch.nn.functional.one_hot(cls_gt, num_species).float(), torch.nn.functional.one_hot(plc_gt, num_region).float(), 1.0\n    \n    batch_size = images.size(0)\n    index = torch.randperm(batch_size).to(images.device)\n    lam = np.random.beta(CONFIG['alpha'], CONFIG['alpha'])\n    \n    mixed_images = lam * images + (1 - lam) * images[index, :]\n    mixed_bio = lam * bio_gt + (1 - lam) * bio_gt[index, :]\n    mixed_reg = lam * reg_gt + (1 - lam) * reg_gt[index, :]\n    \n    cls_onehot = torch.nn.functional.one_hot(cls_gt, num_species).float()\n    mixed_cls = lam * cls_onehot + (1 - lam) * cls_onehot[index, :]\n\n    plc_onehot = torch.nn.functional.one_hot(plc_gt, num_region).float()\n    mixed_plcs = lam * plc_onehot + (1 - lam) * plc_onehot[index, :]\n    \n    return mixed_images, mixed_bio, mixed_reg, mixed_cls, mixed_plcs, lam",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-06T09:56:20.835591Z",
     "iopub.execute_input": "2026-01-06T09:56:20.835923Z",
     "iopub.status.idle": "2026-01-06T09:56:20.842143Z",
     "shell.execute_reply.started": "2026-01-06T09:56:20.835896Z",
     "shell.execute_reply": "2026-01-06T09:56:20.841380Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "class AdvancedDataset(Dataset):\n    def __init__(self, df, img_dir, transform=None, species_map=None, region_map=None):\n        self.df, self.img_dir, self.transform = df, img_dir, transform\n        self.species_map, self.region_map = species_map, region_map\n        \n    def __len__(self): return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img = np.array(Image.open(os.path.join(self.img_dir, row['image_path'])).convert('RGB'))\n        if self.transform: img = self.transform(image=img)['image']\n        \n        bio = torch.tensor(row[TARGET_COLUMNS].values.astype(np.float32))\n        reg = torch.tensor([row['Pre_GSHH_NDVI'], row['Height_Ave_cm']], dtype=torch.float32)\n        cls = torch.tensor(self.species_map[row['Species']], dtype=torch.long)\n        plc = torch.tensor(self.region_map[row['State']], dtype=torch.long)\n        \n        return img, bio, reg, cls, plc\n\ndef competition_metric(y_true, y_pred):\n    N = y_true.shape[0]\n    w = np.tile(TARGET_WEIGHTS, (N, 1)).flatten()\n    y_t, y_p = y_true.flatten(), y_pred.flatten()\n    avg = np.sum(w * y_t) / np.sum(w)\n    res = np.sum(w * (y_t - y_p)**2)\n    tot = np.sum(w * (y_t - avg)**2)\n    return 1 - (res/tot) if tot != 0 else 0",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-06T09:56:24.480528Z",
     "iopub.execute_input": "2026-01-06T09:56:24.481119Z",
     "iopub.status.idle": "2026-01-06T09:56:24.488013Z",
     "shell.execute_reply.started": "2026-01-06T09:56:24.481089Z",
     "shell.execute_reply": "2026-01-06T09:56:24.487400Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "def train_fold(fold, train_df, val_df, species_map, region_map):\n    num_species = len(species_map)\n    num_regions = len(region_map)\n    train_ds = AdvancedDataset(train_df, DATA_DIR, A.Compose([A.Resize(CONFIG['img_h'], CONFIG['img_w']), A.HorizontalFlip(), A.Normalize(), ToTensorV2()]), species_map, region_map)\n    val_ds = AdvancedDataset(val_df, DATA_DIR, A.Compose([A.Resize(CONFIG['img_h'], CONFIG['img_w']), A.Normalize(), ToTensorV2()]), species_map, region_map)\n    \n    loader_t = DataLoader(train_ds, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=2, drop_last=True)\n    loader_v = DataLoader(val_ds, batch_size=CONFIG['batch_size'], shuffle=False)\n    \n    model = AdvancedSwinHydra(num_species=num_species, num_region=num_regions).to(CONFIG['device'])\n    \n    # LOAD PREVIOUS WEIGHTS\n    if CONFIG['resume_path'] != None and os.path.exists(CONFIG['resume_path']):\n        print(f\"Resuming from: {CONFIG['resume_path']}\")\n        sd = torch.load(CONFIG['resume_path'], map_location=CONFIG['device'])\n        model.load_state_dict({k.replace('module.', ''): v for k, v in sd.items()})\n\n    if torch.cuda.device_count() > 1: model = nn.DataParallel(model)\n    \n    optimizer = optim.AdamW(model.parameters(), lr=CONFIG['lr'], weight_decay=0.01)\n    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CONFIG['epochs'])\n    crit_bio = nn.HuberLoss(); crit_reg = nn.MSELoss(); crit_cls = nn.BCEWithLogitsLoss()\n    crit_plc = nn.BCEWithLogitsLoss()\n    scaler = torch.amp.GradScaler('cuda')\n    \n    best_r2 = -float('inf')\n    for epoch in range(CONFIG['epochs']):\n        model.train(); epoch_loss = 0\n        for imgs, bios, regs, clss, plcs in loader_t:\n            imgs, bios, regs, clss, plcs = imgs.to(CONFIG['device']), bios.to(CONFIG['device']), regs.to(CONFIG['device']), clss.to(CONFIG['device']), plcs.to(CONFIG['device'])\n            imgs_m, bios_m, regs_m, clss_m, plcs_m, _ = apply_mixup(imgs, bios, regs, clss, plcs, num_species, num_regions)\n            \n            optimizer.zero_grad()\n            with torch.amp.autocast('cuda', enabled=True):\n                p_bio, p_reg, p_cls, p_plc = model(imgs_m, return_meta=True)\n                loss = crit_bio(p_bio, bios_m) + 0.1*crit_reg(p_reg, regs_m) + 0.2*crit_cls(p_cls, clss_m) +0.2*crit_plc(p_plc, plcs_m)\n            \n            scaler.scale(loss).backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            scaler.step(optimizer); scaler.update(); epoch_loss += loss.item()\n        \n        model.eval(); all_p, all_t = [], []\n        with torch.no_grad():\n            for imgs, bios, _, _, _ in loader_v:\n                all_p.append(model(imgs.to(CONFIG['device'])).cpu().numpy()); all_t.append(bios.numpy())\n        \n        r2 = competition_metric(np.vstack(all_t), np.vstack(all_p))\n        print(f\"Fold {fold} | Ep {epoch+1} | Loss: {epoch_loss/len(loader_t):.4f} | R2: {r2:.4f}\")\n        if r2 > best_r2:\n            best_r2 = r2\n            torch.save(model.state_dict(), f\"{CHECKPOINT_DIR}/best_swinv2_large_region_fold{fold}.pth\")\n        scheduler.step()\n    return best_r2",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-06T09:57:40.490983Z",
     "iopub.execute_input": "2026-01-06T09:57:40.491761Z",
     "iopub.status.idle": "2026-01-06T09:57:40.503455Z",
     "shell.execute_reply.started": "2026-01-06T09:57:40.491731Z",
     "shell.execute_reply": "2026-01-06T09:57:40.502660Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "df = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"))\ndf_wide = df.pivot_table(index=['image_path', 'Sampling_Date', 'Species', 'State', 'Pre_GSHH_NDVI', 'Height_Ave_cm'], columns='target_name', values='target').reset_index()\nspecies_map = {s: i for i, s in enumerate(sorted(df_wide['Species'].unique()))}\nregion_map = {rg: i for i, rg in enumerate(sorted(df_wide['State'].unique()))}\n\nprint(f\"Unique species in training: {len(df_wide['Species'].unique())}\")\nprint(f\"Unique location in training: {len(df_wide['State'].unique())}\")\n\ngkf = GroupKFold(n_splits=CONFIG['n_splits'])\nfor fold, (t, v) in enumerate(gkf.split(df_wide, groups=df_wide['Sampling_Date'])):\n    print(f\"\\n--- Starting Fold {fold} ---\")\n    score = train_fold(fold, df_wide.iloc[t], df_wide.iloc[v], species_map, region_map)\n    print(f\"Fold {fold} Best R2 Score: {score:.4f}\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2026-01-13T14:52:12.571994Z",
     "iopub.execute_input": "2026-01-13T14:52:12.572523Z",
     "iopub.status.idle": "2026-01-13T14:52:12.594089Z",
     "shell.execute_reply.started": "2026-01-13T14:52:12.572478Z",
     "shell.execute_reply": "2026-01-13T14:52:12.593548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Unique species in training: 15\nUnique location in training: 4\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 3
  }
 ]
}