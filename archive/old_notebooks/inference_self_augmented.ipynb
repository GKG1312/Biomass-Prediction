{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# CSIRO Image2Biomass - Self-Augmented Hydra Inference\n",
                "\n",
                "This notebook uses the **Self-Augmented Hydra Model**. \n",
                "It internally predicts environmental signals (NDVI, Height, Species) to improve biomass estimation without requiring any metadata in the test set."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from PIL import Image\n",
                "import timm\n",
                "import albumentations as A\n",
                "from albumentations.pytorch import ToTensorV2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "DATA_DIR = r\"d:\\personalProject\\CSIRO-Image2Biomass_Prediction\\csiro-biomass\"\n",
                "CHECKPOINT_PATH = \"../models_checkpoints/best_self_augmented_fold1.pth\"\n",
                "IMAGE_SIZE = (384, 384)\n",
                "TARGET_COLUMNS = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'GDM_g', 'Dry_Total_g']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SelfAugmentedHydraModel(nn.Module):\n",
                "    \"\"\"\n",
                "    Self-Augmented Hydra Architecture as per USER request:\n",
                "    1. Backbone (Image -> Embeddings)\n",
                "    2. Meta Predictor (Embeddings -> NDVI, Height, Species)\n",
                "       - Species is treated as a single numeric scalar.\n",
                "    3. Final Hydra Predictors (Embeddings + Predicted Meta -> 5 Biomass targets)\n",
                "    \"\"\"\n",
                "    def __init__(self, model_name='convnext_tiny.in12k_ft_in1k', pretrained=False):\n",
                "        super().__init__()\n",
                "        # 1. Backbone\n",
                "        self.backbone = timm.create_model(model_name, pretrained=pretrained, num_classes=0)\n",
                "        embed_dim = self.backbone.num_features\n",
                "        \n",
                "        # 2. Meta Predictor\n",
                "        self.meta_predictor = nn.Sequential(\n",
                "            nn.Linear(embed_dim, 128),\n",
                "            nn.GELU(),\n",
                "            nn.Linear(128, 3) # [NDVI, Height, Species_Index]\n",
                "        )\n",
                "        \n",
                "        # 3. Final Hydra Predictors (Input: Embeddings + 3 Meta Predictions)\n",
                "        fusion_dim = embed_dim + 3\n",
                "        \n",
                "        self.head_clover = nn.Sequential(nn.Linear(fusion_dim, 256), nn.GELU(), nn.Linear(256, 1))\n",
                "        self.head_dead   = nn.Sequential(nn.Linear(fusion_dim, 256), nn.GELU(), nn.Linear(256, 1))\n",
                "        self.head_green  = nn.Sequential(nn.Linear(fusion_dim, 256), nn.GELU(), nn.Linear(256, 1))\n",
                "        self.head_gdm    = nn.Sequential(nn.Linear(fusion_dim, 256), nn.GELU(), nn.Linear(256, 1))\n",
                "        self.head_total  = nn.Sequential(nn.Linear(fusion_dim, 256), nn.GELU(), nn.Linear(256, 1))\n",
                "        \n",
                "    def forward(self, image):\n",
                "        embeddings = self.backbone(image)\n",
                "        pred_meta = self.meta_predictor(embeddings)\n",
                "        combined_input = torch.cat([embeddings, pred_meta], dim=1)\n",
                "        \n",
                "        p_clover = self.head_clover(combined_input)\n",
                "        p_dead   = self.head_dead(combined_input)\n",
                "        p_green  = self.head_green(combined_input)\n",
                "        p_gdm    = self.head_gdm(combined_input)\n",
                "        p_total  = self.head_total(combined_input)\n",
                "        \n",
                "        return torch.cat([p_clover, p_dead, p_green, p_gdm, p_total], dim=1)\n",
                "\n",
                "class SimpleDataset(Dataset):\n",
                "    def __init__(self, df, img_dir, transform=None):\n",
                "        self.df = df\n",
                "        self.img_dir = img_dir\n",
                "        self.transform = transform\n",
                "        \n",
                "    def __len__(self):\n",
                "        return len(self.df)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        row = self.df.iloc[idx]\n",
                "        image = np.array(Image.open(os.path.join(self.img_dir, row['image_path'])).convert('RGB'))\n",
                "        if self.transform:\n",
                "            image = self.transform(image=image)['image']\n",
                "        return image"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_inference():\n",
                "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "    test_df = pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"))\n",
                "    unique_test = test_df.drop_duplicates(subset=['image_path']).copy()\n",
                "    \n",
                "    model = SelfAugmentedHydraModel().to(device)\n",
                "    if os.path.exists(CHECKPOINT_PATH):\n",
                "        model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=device))\n",
                "    model.eval()\n",
                "    \n",
                "    transform = A.Compose([\n",
                "        A.Resize(IMAGE_SIZE[0], IMAGE_SIZE[1]),\n",
                "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
                "        ToTensorV2(),\n",
                "    ])\n",
                "    \n",
                "    dataset = SimpleDataset(unique_test, DATA_DIR, transform)\n",
                "    loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
                "    \n",
                "    results = []\n",
                "    with torch.no_grad():\n",
                "        for i, image in enumerate(loader):\n",
                "            image = image.to(device)\n",
                "            preds = model(image).cpu().numpy()[0]\n",
                "            img_path = unique_test.iloc[i]['image_path']\n",
                "            for j, col in enumerate(TARGET_COLUMNS):\n",
                "                results.append({\n",
                "                    'image_path': img_path,\n",
                "                    'target_name': col,\n",
                "                    'target': max(0, float(preds[j]))\n",
                "                })\n",
                "    \n",
                "    pred_df = pd.DataFrame(results)\n",
                "    submission = test_df[['sample_id', 'image_path', 'target_name']].merge(pred_df, on=['image_path', 'target_name'], how='left')\n",
                "    submission = submission[['sample_id', 'target']]\n",
                "    submission.to_csv(\"submission_self_augmented.csv\", index=False)\n",
                "    print(\"Submission saved to submission_self_augmented.csv\")\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    run_inference()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}