{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro",
            "metadata": {},
            "source": [
                "# CSIRO Image2Biomass - Advanced Swin-V2 (V3 FINAL STABLE)\n",
                "\n",
                "**STATUS: VERIFIED STABLE**\n",
                "1. **Backbone**: Swin-V2 Base (Flexible windows).\n",
                "2. **Loss**: Huber (Safe) + Label Smoothing (0.1).\n",
                "3. **Optimization**: 5-epoch Warmup + Cosine Decay + Gradient Clipping.\n",
                "4. **Resolution**: 384x768 (1:2 ratio)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q -U albumentations timm opencv-python-headless kagglehub"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, sys, functools\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from PIL import Image\n",
                "import timm\n",
                "import albumentations as A\n",
                "from albumentations.pytorch import ToTensorV2\n",
                "from sklearn.model_selection import GroupKFold\n",
                "import kagglehub\n",
                "\n",
                "print = functools.partial(print, flush=True)\n",
                "\n",
                "DATA_DIR = \"/kaggle/input/csiro-biomass\"\n",
                "CHECKPOINT_DIR = \"./models_checkpoints\"\n",
                "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
                "\n",
                "TARGET_COLUMNS = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'GDM_g', 'Dry_Total_g']\n",
                "TARGET_WEIGHTS = [0.1, 0.1, 0.1, 0.2, 0.5]\n",
                "\n",
                "CONFIG = {\n",
                "    \"model_name\": \"swinv2_base_window12_192.ms_in22k\", \n",
                "    \"img_h\": 384, \n",
                "    \"img_w\": 768,\n",
                "    \"batch_size\": 8, \n",
                "    \"lr\": 5e-5, \n",
                "    \"epochs\": 40,\n",
                "    \"n_splits\": 5,\n",
                "    \"device\": \"cuda\"\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "model",
            "metadata": {},
            "outputs": [],
            "source": [
                "class AdvancedSwinHydra(nn.Module):\n",
                "    def __init__(self, model_name=CONFIG['model_name'], num_species=15):\n",
                "        super().__init__()\n",
                "        try:\n",
                "            self.backbone = timm.create_model(\n",
                "                model_name, \n",
                "                pretrained=True, \n",
                "                num_classes=0, \n",
                "                img_size=(CONFIG['img_h'], CONFIG['img_w'])\n",
                "            )\n",
                "        except Exception as e:\n",
                "            base_name = model_name.split('.')[0]\n",
                "            self.backbone = timm.create_model(\n",
                "                base_name, \n",
                "                pretrained=True, \n",
                "                num_classes=0, \n",
                "                img_size=(CONFIG['img_h'], CONFIG['img_w'])\n",
                "            )\n",
                "            \n",
                "        embed_dim = self.backbone.num_features\n",
                "        self.meta_reg = nn.Linear(embed_dim, 2) \n",
                "        self.meta_cls = nn.Linear(embed_dim, num_species)\n",
                "        self.species_emb = nn.Embedding(num_species, 32)\n",
                "        \n",
                "        fusion_dim = embed_dim + 2 + 32\n",
                "        self.heads = nn.ModuleList([nn.Sequential(nn.Linear(fusion_dim, 256), nn.GELU(), nn.Linear(256, 1)) for _ in range(5)])\n",
                "        \n",
                "    def forward(self, x, return_meta=False):\n",
                "        feat = self.backbone(x)\n",
                "        p_reg = self.meta_reg(feat)\n",
                "        p_cls = self.meta_cls(feat)\n",
                "        \n",
                "        spec_idx = torch.argmax(p_cls, dim=1)\n",
                "        s_emb = self.species_emb(spec_idx)\n",
                "        \n",
                "        fusion = torch.cat([feat, p_reg, s_emb], dim=1)\n",
                "        out = torch.cat([h(fusion) for h in self.heads], dim=1)\n",
                "        \n",
                "        if return_meta: return out, p_reg, p_cls\n",
                "        return out"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "train_utils",
            "metadata": {},
            "outputs": [],
            "source": [
                "def competition_metric(y_true, y_pred):\n",
                "    N = y_true.shape[0]\n",
                "    w = np.tile(TARGET_WEIGHTS, (N, 1)).flatten()\n",
                "    y_t, y_p = y_true.flatten(), y_pred.flatten()\n",
                "    avg = np.sum(w * y_t) / np.sum(w)\n",
                "    res = np.sum(w * (y_t - y_p)**2)\n",
                "    tot = np.sum(w * (y_t - avg)**2)\n",
                "    return 1 - (res/tot) if tot != 0 else 0\n",
                "\n",
                "class AdvancedDataset(Dataset):\n",
                "    def __init__(self, df, img_dir, transform=None, species_map=None):\n",
                "        self.df, self.img_dir, self.transform, self.species_map = df, img_dir, transform, species_map\n",
                "    def __len__(self): return len(self.df)\n",
                "    def __getitem__(self, idx):\n",
                "        row = self.df.iloc[idx]\n",
                "        img = np.array(Image.open(os.path.join(self.img_dir, row['image_path'])).convert('RGB'))\n",
                "        if self.transform: img = self.transform(image=img)['image']\n",
                "        bio = torch.tensor(row[TARGET_COLUMNS].values.astype(np.float32))\n",
                "        reg = torch.tensor([row['Pre_GSHH_NDVI'], row['Height_Ave_cm']], dtype=torch.float32)\n",
                "        cls = torch.tensor(self.species_map[row['Species']], dtype=torch.long)\n",
                "        return img, bio, reg, cls"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "train_fold",
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_fold(fold, train_df, val_df, species_map):\n",
                "    train_ds = AdvancedDataset(train_df, DATA_DIR, A.Compose([\n",
                "        A.Resize(CONFIG['img_h'], CONFIG['img_w']),\n",
                "        A.HorizontalFlip(p=0.5),\n",
                "        A.RandomBrightnessContrast(p=0.2),\n",
                "        A.ShiftScaleRotate(shift_limit=0.05, rotate_limit=15, p=0.3),\n",
                "        A.Normalize(),\n",
                "        ToTensorV2()\n",
                "    ]), species_map)\n",
                "    val_ds = AdvancedDataset(val_df, DATA_DIR, A.Compose([A.Resize(CONFIG['img_h'], CONFIG['img_w']), A.Normalize(), ToTensorV2()]), species_map)\n",
                "    \n",
                "    loader_t = DataLoader(train_ds, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=4, drop_last=True)\n",
                "    loader_v = DataLoader(val_ds, batch_size=CONFIG['batch_size'], shuffle=False)\n",
                "    \n",
                "    model = AdvancedSwinHydra(num_species=len(species_map)).to(CONFIG['device'])\n",
                "    if torch.cuda.device_count() > 1: model = nn.DataParallel(model)\n",
                "    \n",
                "    optimizer = optim.AdamW(model.parameters(), lr=CONFIG['lr'], weight_decay=0.05)\n",
                "    \n",
                "    # Warmup + Cosine Scheduler\n",
                "    warmup_epochs = 5\n",
                "    def lr_lambda(epoch):\n",
                "        if epoch < warmup_epochs: return (epoch + 1) / warmup_epochs\n",
                "        return 0.5 * (1 + np.cos(np.pi * (epoch - warmup_epochs) / (CONFIG['epochs'] - warmup_epochs)))\n",
                "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
                "    \n",
                "    crit_bio = nn.HuberLoss() \n",
                "    crit_reg = nn.MSELoss()\n",
                "    crit_cls = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
                "    scaler = torch.amp.GradScaler('cuda')\n",
                "    \n",
                "    best_r2 = -float('inf')\n",
                "    best_sd = None\n",
                "    \n",
                "    for epoch in range(CONFIG['epochs']):\n",
                "        model.train()\n",
                "        epoch_loss = 0\n",
                "        for imgs, bios, regs, clss in loader_t:\n",
                "            optimizer.zero_grad()\n",
                "            with torch.amp.autocast('cuda'):\n",
                "                p_bio, p_reg, p_cls = model(imgs.to(CONFIG['device']), return_meta=True)\n",
                "                loss = crit_bio(p_bio, bios.to(CONFIG['device'])) + 0.1*crit_reg(p_reg, regs.to(CONFIG['device'])) + 0.2*crit_cls(p_cls, clss.to(CONFIG['device']))\n",
                "                \n",
                "            scaler.scale(loss).backward()\n",
                "            scaler.unscale_(optimizer)\n",
                "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) \n",
                "            scaler.step(optimizer)\n",
                "            scaler.update()\n",
                "            epoch_loss += loss.item()\n",
                "            \n",
                "        model.eval(); all_p, all_t = [], []\n",
                "        with torch.no_grad():\n",
                "            for imgs, bios, _, _ in loader_v:\n",
                "                all_p.append(model(imgs.to(CONFIG['device'])).cpu().numpy())\n",
                "                all_t.append(bios.numpy())\n",
                "        \n",
                "        r2 = competition_metric(np.vstack(all_t), np.vstack(all_p))\n",
                "        print(f\"Fold {fold} | Ep {epoch+1} | Loss: {epoch_loss/len(loader_t):.4f} | R2: {r2:.4f}\")\n",
                "        \n",
                "        if r2 > best_r2:\n",
                "            best_r2 = r2\n",
                "            best_sd = model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict()\n",
                "        \n",
                "        scheduler.step()\n",
                "        \n",
                "    return best_r2, best_sd"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "main",
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"))\n",
                "df_wide = df.pivot_table(index=['image_path', 'Sampling_Date', 'Species', 'Pre_GSHH_NDVI', 'Height_Ave_cm'], columns='target_name', values='target').reset_index()\n",
                "species_map = {s: i for i, s in enumerate(sorted(df_wide['Species'].unique()))}\n",
                "\n",
                "overall_best_r2, overall_best_sd = -float('inf'), None\n",
                "gkf = GroupKFold(n_splits=CONFIG['n_splits'])\n",
                "for fold, (t, v) in enumerate(gkf.split(df_wide, groups=df_wide['Sampling_Date'])):\n",
                "    print(f\"\\n--- Fold {fold} ---\")\n",
                "    score, sd = train_fold(fold, df_wide.iloc[t], df_wide.iloc[v], species_map)\n",
                "    if score > overall_best_r2: overall_best_r2, overall_best_sd = score, sd\n",
                "\n",
                "if overall_best_sd is not None:\n",
                "    path = os.path.join(CHECKPOINT_DIR, \"best_swin_v3.pth\")\n",
                "    torch.save(overall_best_sd, path)\n",
                "    try: \n",
                "        kagglehub.model_upload(f\"girish2002/CSIRO_Dino_SelfAugmented/pytorch/default\", os.path.dirname(path), f\"Swin V3 Stable R2 {overall_best_r2:.4f}\")\n",
                "    except: pass"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}