{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro",
            "metadata": {},
            "source": [
                "# CSIRO Image2Biomass - Advanced Swin Inference (STRICT OFFLINE)\n",
                "\n",
                "This notebook performs inference using the `AdvancedSwinHydra`. It is strictly configured for **Internet Off** environments."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from PIL import Image\n",
                "import timm\n",
                "import albumentations as A\n",
                "from albumentations.pytorch import ToTensorV2\n",
                "\n",
                "# ==========================================\n",
                "# CONFIGURATION\n",
                "# ==========================================\n",
                "DATA_DIR = r\"D:\\personalProject\\CSIRO-Image2Biomass_Prediction\\csiro-biomass\"\n",
                "CHECKPOINT_PATH = r\"D:\\personalProject\\CSIRO-Image2Biomass_Prediction\\models_checkpoints\\best_swinv2_large_ft_fold2.pth\"\n",
                "\n",
                "# USE BASE NAME ONLY - PREVENTS TIMM FROM CALLING HUGGINGFACE HUB\n",
                "MODEL_NAME = \"swinv2_large_window12_192.ms_in22k\"\n",
                "IMAGE_SIZE = (384, 768)\n",
                "TARGET_COLUMNS = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'GDM_g', 'Dry_Total_g']\n",
                "NUM_SPECIES = 15\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "model",
            "metadata": {},
            "outputs": [],
            "source": [
                "class AdvancedSwinHydra(nn.Module):\n",
                "    def __init__(self, model_name=MODEL_NAME, num_species=NUM_SPECIES):\n",
                "        super().__init__()\n",
                "        # FORCED OFFLINE: pretrained=False is hardcoded here to block all network calls\n",
                "        self.backbone = timm.create_model(\n",
                "            model_name, \n",
                "            pretrained=False, \n",
                "            num_classes=0, \n",
                "            img_size=IMAGE_SIZE\n",
                "        )\n",
                "        embed_dim = self.backbone.num_features\n",
                "        \n",
                "        self.meta_reg = nn.Linear(embed_dim, 2) \n",
                "        self.meta_cls = nn.Linear(embed_dim, num_species)\n",
                "        self.species_emb = nn.Embedding(num_species, 32)\n",
                "        \n",
                "        fusion_dim = embed_dim + 2 + 32\n",
                "        self.heads = nn.ModuleList([\n",
                "            nn.Sequential(nn.Linear(fusion_dim, 256), nn.GELU(), nn.Linear(256, 1))\n",
                "            for _ in range(5)\n",
                "        ])\n",
                "        \n",
                "    def forward(self, x):\n",
                "        feat = self.backbone(x)\n",
                "        p_reg = self.meta_reg(feat)\n",
                "        p_cls = self.meta_cls(feat)\n",
                "        \n",
                "        spec_idx = torch.argmax(p_cls, dim=1)\n",
                "        s_emb = self.species_emb(spec_idx)\n",
                "        \n",
                "        fusion = torch.cat([feat, p_reg, s_emb], dim=1)\n",
                "        out = torch.cat([h(fusion) for h in self.heads], dim=1)\n",
                "        return out"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "dataset",
            "metadata": {},
            "outputs": [],
            "source": [
                "class SimpleDataset(Dataset):\n",
                "    def __init__(self, df, img_dir, transform=None):\n",
                "        self.df, self.img_dir, self.transform = df, img_dir, transform\n",
                "    def __len__(self): return len(self.df)\n",
                "    def __getitem__(self, idx):\n",
                "        row = self.df.iloc[idx]\n",
                "        img = Image.open(os.path.join(self.img_dir, row['image_path'])).convert(\"RGB\")\n",
                "        img = np.array(img)\n",
                "        if self.transform: img = self.transform(image=img)[\"image\"]\n",
                "        return img"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "inference",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading weights from: D:\\personalProject\\CSIRO-Image2Biomass_Prediction\\models_checkpoints\\best_swinv2_large_ft_fold2.pth\n",
                        "Weights loaded successfully.\n",
                        "                     sample_id     target\n",
                        "0   ID1001187975__Dry_Clover_g   0.411185\n",
                        "1     ID1001187975__Dry_Dead_g  28.347141\n",
                        "2    ID1001187975__Dry_Green_g  27.112358\n",
                        "3    ID1001187975__Dry_Total_g  58.057373\n",
                        "4          ID1001187975__GDM_g  29.188145\n",
                        "5      ID4464212__Dry_Clover_g   0.000000\n",
                        "6        ID4464212__Dry_Dead_g  13.171807\n",
                        "7       ID4464212__Dry_Green_g  32.280479\n",
                        "8       ID4464212__Dry_Total_g  46.282780\n",
                        "9             ID4464212__GDM_g  31.856617\n",
                        "10     ID6269659__Dry_Clover_g  14.796210\n",
                        "11       ID6269659__Dry_Dead_g   4.284080\n",
                        "12      ID6269659__Dry_Green_g  33.170723\n",
                        "13      ID6269659__Dry_Total_g  57.305706\n",
                        "14            ID6269659__GDM_g  51.166885\n",
                        "15     ID7850481__Dry_Clover_g  13.952002\n",
                        "16       ID7850481__Dry_Dead_g   0.745448\n",
                        "17      ID7850481__Dry_Green_g   8.568916\n",
                        "18      ID7850481__Dry_Total_g  28.235245\n",
                        "19            ID7850481__GDM_g  26.674339\n",
                        "20     ID8209776__Dry_Clover_g   8.653509\n",
                        "21       ID8209776__Dry_Dead_g  14.951909\n",
                        "22      ID8209776__Dry_Green_g  12.832935\n",
                        "23      ID8209776__Dry_Total_g  37.749146\n",
                        "24            ID8209776__GDM_g  22.634071\n",
                        "25    ID12390962__Dry_Clover_g   0.000000\n",
                        "26      ID12390962__Dry_Dead_g  20.393957\n",
                        "27     ID12390962__Dry_Green_g  16.100510\n",
                        "28     ID12390962__Dry_Total_g  35.897148\n",
                        "29           ID12390962__GDM_g  15.067243\n",
                        "30    ID13162390__Dry_Clover_g   2.779630\n",
                        "31      ID13162390__Dry_Dead_g   3.342139\n",
                        "32     ID13162390__Dry_Green_g  21.980015\n",
                        "33     ID13162390__Dry_Total_g  28.396746\n",
                        "34           ID13162390__GDM_g  24.619043\n",
                        "35    ID21377800__Dry_Clover_g   0.000000\n",
                        "36      ID21377800__Dry_Dead_g  27.369755\n",
                        "37     ID21377800__Dry_Green_g  12.662477\n",
                        "38     ID21377800__Dry_Total_g  41.687538\n",
                        "39           ID21377800__GDM_g  12.390090\n",
                        "Submission saved to submission.csv\n"
                    ]
                }
            ],
            "source": [
                "def run_inference():\n",
                "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "    test_df = pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"))\n",
                "    unique_test = test_df.drop_duplicates(subset=['image_path']).copy()\n",
                "    \n",
                "    # INSTANTIATION\n",
                "    model = AdvancedSwinHydra().to(device)\n",
                "    \n",
                "    if os.path.exists(CHECKPOINT_PATH):\n",
                "        print(f\"Loading weights from: {CHECKPOINT_PATH}\")\n",
                "        state_dict = torch.load(CHECKPOINT_PATH, map_location=device)\n",
                "        state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
                "        model.load_state_dict(state_dict)\n",
                "        print(\"Weights loaded successfully.\")\n",
                "    else:\n",
                "        print(f\"CRITICAL ERROR: Weight file not found at {CHECKPOINT_PATH}\")\n",
                "        return\n",
                "        \n",
                "    model.eval()\n",
                "    transform = A.Compose([\n",
                "        A.Resize(IMAGE_SIZE[0], IMAGE_SIZE[1]),\n",
                "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
                "        ToTensorV2(),\n",
                "    ])\n",
                "    \n",
                "    dataset = SimpleDataset(unique_test, DATA_DIR, transform)\n",
                "    loader = DataLoader(dataset, batch_size=8, shuffle=False)\n",
                "    \n",
                "    results = []\n",
                "    with torch.no_grad():\n",
                "        for i, image in enumerate(loader):\n",
                "            image = image.to(device).float()\n",
                "            # Change 2: Predict for the whole batch\n",
                "            batch_preds = model(image).cpu().numpy() \n",
                "            \n",
                "            # Change 3: Iterate THROUGH the batch\n",
                "            for b in range(batch_preds.shape[0]):\n",
                "                # Calculate the exact row in unique_test\n",
                "                global_idx = i * loader.batch_size + b\n",
                "                img_path = unique_test.iloc[global_idx]['image_path']\n",
                "                \n",
                "                preds = batch_preds[b]\n",
                "                for j, col in enumerate(TARGET_COLUMNS):\n",
                "                    results.append({\n",
                "                        'image_path': img_path,\n",
                "                        'target_name': col,\n",
                "                        'target': max(0.0, float(preds[j]))\n",
                "                    })\n",
                "    \n",
                "    pred_df = pd.DataFrame(results)\n",
                "    submission = test_df[['sample_id', 'image_path', 'target_name']].merge(pred_df, on=['image_path', 'target_name'], how='left')\n",
                "    submission = submission[['sample_id', 'target']]\n",
                "    submission.to_csv(\"submission.csv\", index=False)\n",
                "    print(submission)\n",
                "    print(\"Submission saved to submission.csv\")\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    run_inference()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "pips",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
