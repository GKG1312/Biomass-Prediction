{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "intro",
      "metadata": {},
      "source": [
        "# CSIRO DINOv2 Tiling + Mixup Strategy (Multi-GPU Training)\n",
        "\n",
        "**Architecture:**\n",
        "1. **Global Stream**: Full image at `392x784` for environmental context.\n",
        "2. **Local Stream**: Two high-res `1000x1000` crops (original scale) resized to `392x392`.\n",
        "3. **Regularization**: Mixup applied synchronously to both streams.\n",
        "4. **Speed**: Optimized for Dual T4 GPUs (`nn.DataParallel`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "setup",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q -U albumentations timm opencv-python-headless\n\n",
        "import os, sys, functools, json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import timm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from sklearn.model_selection import GroupKFold\n\n",
        "print = functools.partial(print, flush=True)\n",
        "DATA_DIR = '/kaggle/input/csiro-biomass'\n",
        "CHECKPOINT_DIR = './models_checkpoints'\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n\n",
        "# STRICT ALPHABETICAL ORDER\n",
        "TARGET_COLUMNS = ['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g', 'GDM_g']\n",
        "TARGET_WEIGHTS = [0.1, 0.1, 0.1, 0.5, 0.2]\n\n",
        "CONFIG = {\n",
        "    'model_name': 'vit_base_patch14_dinov2.lvd142m', \n",
        "    'img_h': 392, \n",
        "    'img_w': 784,\n",
        "    'tile_size': 392,\n",
        "    'batch_size': 16,\n",
        "    'lr': 1e-4,\n",
        "    'epochs': 25,\n",
        "    'mixup_prob': 0.5,\n",
        "    'n_splits': 5,\n",
        "    'resume_path': None, \n",
        "    'device': 'cuda'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "model",
      "metadata": {},
      "outputs": [],
      "source": [
        "class GlobalLocalDinoHydra(nn.Module):\n",
        "    def __init__(self, model_name=CONFIG['model_name'], num_species=15):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(model_name, pretrained=True, num_classes=0, dynamic_img_size=True)\n",
        "        embed_dim = self.backbone.num_features\n",
        "        self.meta_reg = nn.Linear(embed_dim * 2, 2) \n",
        "        self.meta_cls = nn.Linear(embed_dim * 2, num_species)\n",
        "        self.species_emb = nn.Embedding(num_species, 32)\n",
        "        fusion_dim = (embed_dim * 2) + 2 + 32\n",
        "        self.heads = nn.ModuleList([\n",
        "            nn.Sequential(nn.Linear(fusion_dim, 512), nn.GELU(), nn.Linear(512, 1))\n",
        "            for _ in range(5)\n",
        "        ])\n",
        "    def forward(self, x_global, x_tiles):\n",
        "        f_g = self.backbone(x_global)\n",
        "        B, N, C, H, W = x_tiles.shape\n",
        "        f_t = self.backbone(x_tiles.view(B*N, C, H, W)).view(B, N, -1).mean(dim=1)\n",
        "        vis = torch.cat([f_g, f_t], dim=1)\n",
        "        pr, pc = self.meta_reg(vis), self.meta_cls(vis)\n",
        "        se = self.species_emb(torch.argmax(pc, dim=1))\n",
        "        f = torch.cat([vis, pr, se], dim=1)\n",
        "        return torch.cat([h(f) for h in self.heads], dim=1), pr, pc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dataset",
      "metadata": {},
      "outputs": [],
      "source": [
        "class TiledDataset(Dataset):\n",
        "    def __init__(self, df, tf_g, tf_t, sm):\n",
        "        self.df, self.tf_g, self.tf_t, self.sm = df, tf_g, tf_t, sm\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img = np.array(Image.open(os.path.join(DATA_DIR, row['image_path'])).convert('RGB'))\n",
        "        mid = img.shape[1] // 2\n",
        "        g = self.tf_g(image=img)['image']\n",
        "        t = torch.stack([self.tf_t(image=img[:, :mid])['image'], self.tf_t(image=img[:, mid:])['image']])\n",
        "        b = torch.tensor(row[TARGET_COLUMNS].values.astype(np.float32))\n",
        "        r = torch.tensor([row['Pre_GSHH_NDVI'], row['Height_Ave_cm']], dtype=torch.float32)\n",
        "        c = torch.tensor(self.sm[row['Species']], dtype=torch.long)\n",
        "        return g, t, b, r, c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "logic",
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_mixup(g, t, b, r, c, ns):\n",
        "    if np.random.rand() > CONFIG['mixup_prob']: \n",
        "        return g, t, b, r, nn.functional.one_hot(c, ns).float(), 1.0\n",
        "    i = torch.randperm(g.size(0)).to(g.device); l = np.random.beta(1.0, 1.0)\n",
        "    g, t = l*g + (1-l)*g[i], l*t + (1-l)*t[i]\n",
        "    b, r = l*b + (1-l)*b[i], l*r + (1-l)*r[i]\n",
        "    c_oh = nn.functional.one_hot(c, ns).float()\n",
        "    return g, t, b, r, l*c_oh + (1-l)*c_oh[i], l\n\n",
        "def train_fold(fold, t_df, v_df, sm):\n",
        "    ns = len(sm)\n",
        "    tf_g = A.Compose([A.Resize(392, 784), A.HorizontalFlip(), A.Normalize(), ToTensorV2()])\n",
        "    tf_t = A.Compose([A.Resize(392, 392), A.HorizontalFlip(), A.Normalize(), ToTensorV2()])\n",
        "    ld_t = DataLoader(TiledDataset(t_df, tf_g, tf_t, sm), batch_size=CONFIG['batch_size'], shuffle=True, num_workers=4, drop_last=True)\n",
        "    ld_v = DataLoader(TiledDataset(v_df, tf_g, tf_t, sm), batch_size=CONFIG['batch_size'], shuffle=False, num_workers=4)\n",
        "    \n",
        "    m = GlobalLocalDinoHydra(num_species=ns).cuda()\n",
        "    if CONFIG['resume_path']:\n",
        "        sd = torch.load(CONFIG['resume_path'], map_location='cuda')\n",
        "        m.load_state_dict({k.replace('module.',''): v for k,v in sd.items()})\n",
        "    if torch.cuda.device_count() > 1: m = nn.DataParallel(m)\n",
        "    \n",
        "    # STABILITY: Lower LR + Weight Decay\n",
        "    opt = optim.AdamW(m.parameters(), lr=5e-5, weight_decay=0.01)\n",
        "    scaler = torch.amp.GradScaler('cuda') # Instantiate OUTSIDE loop\n",
        "    crits = [nn.HuberLoss(), nn.MSELoss(), nn.BCEWithLogitsLoss()]\n",
        "    \n",
        "    best_r2 = -float('inf')\n",
        "    for e in range(CONFIG['epochs']):\n",
        "        m.train(); loss_acc = 0\n",
        "        for g, t, b, r, c in ld_t:\n",
        "            g, t, b, r, c = g.cuda(), t.cuda(), b.cuda(), r.cuda(), c.cuda()\n",
        "            gm, tm, bm, rm, cm, _ = apply_mixup(g, t, b, r, c, ns)\n",
        "            opt.zero_grad()\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                pb, pr, pc = m(gm, tm)\n",
        "                loss = crits[0](pb, bm) + 0.1*crits[1](pr, rm) + 0.2*crits[2](pc, cm)\n",
        "            \n",
        "            # STABILITY: Correct AMP scaling\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(opt)\n",
        "            nn.utils.clip_grad_norm_(m.parameters(), 1.0) # Prevents NaN\n",
        "            scaler.step(opt)\n",
        "            scaler.update()\n",
        "            loss_acc += loss.item()\n",
        "            \n",
        "        m.eval(); ap, at = [], []\n",
        "        with torch.no_grad():\n",
        "            for g, t, b, _, _ in ld_v:\n",
        "                pb, _, _ = m(g.cuda(), t.cuda())\n",
        "                ap.append(pb.cpu().numpy()); at.append(b.numpy())\n",
        "        \n",
        "        y_t, y_p = np.vstack(at), np.vstack(ap)\n",
        "        # DENOM Guard: prevent division by zero or NaN\n",
        "        denom = np.sum((y_t - y_t.mean())**2)\n",
        "        r2 = 1 - np.sum((y_t-y_p)**2)/denom if denom > 0 else 0.0\n",
        "        print(f'Fold {fold} | Ep {e+1} | R2: {r2:.4f} | Loss: {loss_acc/len(ld_t):.4f}')\n",
        "        if r2 > best_r2:\n",
        "            best_r2 = r2\n",
        "            save_sd = m.module.state_dict() if hasattr(m, \"module\") else m.state_dict()\n",
        "            torch.save(save_sd, f\"dino_fold{fold}.pth\")\n",
        "    return best_r2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "main",
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('/kaggle/input/csiro-biomass/train.csv')\n",
        "w = df.pivot_table(index=['image_path','Sampling_Date','Species','Pre_GSHH_NDVI','Height_Ave_cm'], columns='target_name', values='target').reset_index()\n",
        "sm = {s: i for i, s in enumerate(sorted(w['Species'].unique()))}\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "for f, (ti, vi) in enumerate(gkf.split(w, groups=w['Sampling_Date'])):\n",
        "    if f > 1: break # Train 2 folds initially\n",
        "    train_fold(f, w.iloc[ti], w.iloc[vi], sm)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "isInternetEnabled": true,
      "isGpuEnabled": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}